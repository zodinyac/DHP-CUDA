\section{Описание программной реализации}

Программная реализация была выполнена на языке C с использованием стандарта \texttt{C11}. Для распараллеливания решения задачи на разных вычислительных узлах использовалась библиотека \texttt{MPI}. Для распараллеливания в рамках одного вычислительного узла (содержащего несколько вычислительных ядер) была использована технология OpenMP. Исходный код содержит собственную библиотеку для более удобной работы с динамическими массивами в языке C \texttt{array.h}.

В разработанной программе перед решением поставленной задачи инициализируется декартова топология, разбивается прямоугольник $\Pi$ и инициализируется сетка и используемые массивы.

После чего начинается итерационный процесс, останавливающийся при выполнении ранее указанного неравенства (\ref{eq:stop}). На каждой итерации каждый процесс получает и отправляет своим соседям свои граничные строки и столбцы (функция \texttt{neighbors\_exchange}), а затем использует эти значения. Происходит следующее число обменов:
\begin{enumerate}[label=\arabic*)]
  \item \textbf{0}, если процесс граничный в топологии,
  \item \textbf{2}, если процесс угловой,
  \item \textbf{3}, если процесс боковой,
  \item \textbf{4}, если процесс внутренний.
\end{enumerate}

При вычислении коэффициентов $\alpha$ и $\tau$ каждый процесс получает и суммирует вычисленные значения со значениями с других процессов.

После окончания итерации процессы вычисляют значение нормы по указанной в предыдущем разделе формуле, затем обмениваются вычисленными значениями и каждый процесс хранит максимальное, после чего проверяется критерий завершения итерационного процесса (\ref{eq:stop}).

Затем в процессе с ранком 0 происходит сбор решения от всех процессов в единый массив (функция \texttt{make\_solution}).

\subsection{CUDA}

По условиям задания было необходимо реализовать версию программы с использованием \texttt{CUDA}. Это было реализовано следующим образом.

Для распараллеливания решения задачи на разных вычислительных узлах, как уже было сказано, использовалась библиотека \texttt{MPI}. Для распараллеливания в рамках одного вычислительного узла была использована технология \texttt{CUDA}.

Все основные вычисления осуществляются с использованием графических процессоров. Реализованы следующие ядра:
\begin{enumerate}[label=\arabic*)]
  \item ядра, рассчитывающие различные вектора для решения задачи;
  \item ядра, рассчитывающие скалярные произведения;
  \item ядро для нахождения нормы;
  \item ядро, вычисляющее погрешность решения.
\end{enumerate}

Реализованная программа содержит следующие файлы.
\begin{enumerate}[label=\arabic*)]
  \item \texttt{array.h}~-- файл для удобной работы с массивами на языке \texttt{C}.
  \item \texttt{cuda.cu}~-- исходный код ядер и функции для их вызова.
  \item \texttt{cuda.h}~-- заголовки функций, содержащихся в файле \texttt{cuda.cu}.
  \item \texttt{cuda\_utils.h}~-- вспомогательные определения и функции.
  \item \texttt{definitions.h}~-- вспомогательные определения.
  \item \texttt{dhp-cuda.c}~-- основной код программы.
  \item \texttt{makefile}~-- \texttt{make}-файл для удобства сборки.
\end{enumerate}

\clearpage
